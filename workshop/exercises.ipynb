{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbt with Databricks - Hands-on Exercises\n",
    "\n",
    "Welcome to the dbt training session! In this workshop, you'll learn to build data transformations using the medallion architecture pattern.\n",
    "\n",
    "![Medallion Architecture Overview](z_assets/medallion-architecture-overview.png)\n",
    "\n",
    "## What You'll Build\n",
    "- **Bronze Layer**: Raw TPC-H data (already provided)\n",
    "- **Silver Layer**: Cleansed data with surrogate keys and SCD2 tracking\n",
    "- **Gold Layer**: Dimensional model for analytics\n",
    "\n",
    "## Prerequisites\n",
    "- Access to Databricks workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: dbt Setup\n",
    "\n",
    "### Goal\n",
    "Initialize your dbt project and establish connection to Databricks.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1.1 Initialize virtual environment\n",
    "```bash\n",
    "python -m venv .venv\n",
    "\n",
    "# Windows\n",
    ".venv\\Scripts\\activate\n",
    "\n",
    "# Mac/Linux\n",
    ". .venv/bin/activate\n",
    "```\n",
    "\n",
    "#### 1.1 Initialize dbt Project\n",
    "```bash\n",
    "pip install -r requirements-dev.txt\n",
    "\n",
    "dbt init\n",
    "dbt debug\n",
    "```\n",
    "\n",
    "#### 1.2 Review Connection\n",
    "Review `C:\\Users\\<Username>\\.dbt\\profiles.yml` (Windows) or `~/.dbt/profiles.yml` (Mac/Linux) and optionally copy the file to dbt-workshop:\n",
    "```yaml\n",
    "dbt-workshop:\n",
    "  outputs:\n",
    "    dev:\n",
    "      catalog: dbt-workshop\n",
    "      host: adb-673939630363416.16.azuredatabricks.net\n",
    "      http_path: /sql/1.0/warehouses/42d4ebf47e760187\n",
    "      schema: <YOUR INITIALS>\n",
    "      threads: 4\n",
    "      token: <PAT>\n",
    "      type: databricks\n",
    "  target: dev\n",
    "```\n",
    "\n",
    "#### 1.3 Test Connection\n",
    "```bash\n",
    "dbt debug\n",
    "```\n",
    "\n",
    "### Expected Outcome\n",
    "- `dbt debug` shows all green checkmarks (except git)\n",
    "- Connection to Databricks is successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Explore Bronze Data\n",
    "\n",
    "### Goal\n",
    "Understand the TPC-H source data structure.\n",
    "\n",
    "### TPC-H Data Model\n",
    "![TPC-H Data Model](z_assets/tpc-h.png)\n",
    "\n",
    ">> The listed columns are not correct. The correct column names have prefixes as seen in the paranthesis after the table name. E.g., `custkey` of the table **custoer** is actually `c_custkey`. You have to keep that in mind during the exercises.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 2.1 Login to the Databricks Workspace\n",
    "1. Go to: https://adb-673939630363416.16.azuredatabricks.net/\n",
    "2. On the menu click on \"SQL Editor\"\n",
    "3. Make sure that you have the catalog 'dbt-workshop' and the schema 'default' selected.\n",
    "![image.png](z_assets/exercise-2-1.png)\n",
    "\n",
    "#### 2.2 Explore Tables\n",
    "Explore the tables in the catalog using the UI.\n",
    "\n",
    "Run these queries in Databricks to understand the data:\n",
    "\n",
    "```sql\n",
    "-- Check available tables\n",
    "SHOW TABLES IN bronze;\n",
    "\n",
    "-- Explore customer data\n",
    "SELECT * FROM bronze.customer LIMIT 10;\n",
    "DESCRIBE bronze.customer;\n",
    "\n",
    "-- Check data volumes\n",
    "SELECT 'customer' as table_name, COUNT(*) as row_count FROM bronze.customer\n",
    "UNION ALL\n",
    "SELECT 'orders', COUNT(*) FROM bronze.orders\n",
    "UNION ALL\n",
    "SELECT 'lineitem', COUNT(*) FROM bronze.lineitem;\n",
    "```\n",
    "\n",
    "### Tables Available\n",
    "- `customer`: Customer information\n",
    "- `orders`: Customer orders \n",
    "- `lineitem`: Order line items (largest table)\n",
    "- `part`: Product parts\n",
    "- `partsupp`: Part-supplier relationships\n",
    "- `supplier`: Supplier information\n",
    "- `nation`: Countries\n",
    "- `region`: Geographic regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Silver Layer - Basic Models\n",
    "\n",
    "### Goal\n",
    "Create your first dbt models with renamed tables and columns.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 3.1 Create Source Configuration\n",
    "Create `src/models/bronze/sources.yml`:\n",
    "```yaml\n",
    "version: 2\n",
    "\n",
    "sources:\n",
    "  - name: bronze\n",
    "    description: 'Raw TPC-H data'\n",
    "    tables:\n",
    "      - name: customer\n",
    "      - name: orders\n",
    "      - name: lineitem\n",
    "      - name: part\n",
    "      - name: partsupp\n",
    "      - name: supplier\n",
    "      - name: nation\n",
    "      - name: region\n",
    "```\n",
    "\n",
    "#### 3.2 Configure Silver Models\n",
    "Create `src/models/silver/schema.yml`:\n",
    "```yaml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: customers\n",
    "    description: 'Cleansed customer data'\n",
    "  - name: orders\n",
    "    description: 'Cleansed orders data'\n",
    "  - name: lineitems\n",
    "    description: 'Cleansed line item data'\n",
    "  - name: parts\n",
    "    description: 'Cleansed parts data'\n",
    "  - name: suppliers\n",
    "    description: 'Cleansed supplier data'\n",
    "  - name: nations\n",
    "    description: 'Cleansed nation data'\n",
    "  - name: regions\n",
    "    description: 'Cleansed region data'\n",
    "```\n",
    "\n",
    "#### 3.3 Create Silver Models\n",
    "\n",
    "Create `src/models/silver/customers.sql`:\n",
    "```sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT \n",
    "    c_custkey as customer_id,\n",
    "    c_name as customer_name,\n",
    "    c_address as customer_address,\n",
    "    c_nationkey as nation_id,\n",
    "    c_phone as customer_phone,\n",
    "    c_acctbal as account_balance,\n",
    "    c_mktsegment as market_segment,\n",
    "    c_comment as customer_comment\n",
    "FROM {{ source('bronze', 'customer') }}\n",
    "```\n",
    "\n",
    "You don't have to specify `{{ config(materialized='table') }}` within the model, as we have already a project-wide setting for table materialization specified in `dbt_project.yml`.\n",
    "\n",
    "Create similar models for:\n",
    "- `orders.sql` (rename orderkey → order_id, custkey → customer_id, etc.)\n",
    "- `lineitems.sql` (rename orderkey → order_id, partkey → part_id, etc.)\n",
    "- `parts.sql`, `suppliers.sql`, `nations.sql`, `regions.sql`\n",
    "- Rules:\n",
    "  - Table names in silver are plural\n",
    "  - If it is a comment field, then add the entity name as prefix: `c_customer` → `customer_comment`.\n",
    "  - Abbreviations spelled out: `qty` → `quantity`, etc.\n",
    "  - snake_case for columns containing multiple words\n",
    "- You can skip `partsupp` as this table is not required for our use case\n",
    "\n",
    "#### 3.4 Run Your Models\n",
    "```bash\n",
    "dbt run --select silver\n",
    "\n",
    "# Run all models\n",
    "dbt run\n",
    "```\n",
    "\n",
    "### Success Criteria\n",
    "- All silver models run successfully\n",
    "- Tables have consistent naming (plural, snake_case)\n",
    "- Columns are renamed for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Silver Layer - Surrogate Keys & Snapshots\n",
    "\n",
    "### Goal\n",
    "Add surrogate keys and implement SCD2 tracking with snapshots.\n",
    "\n",
    "### Silver Layer Data Model\n",
    "Your target silver layer model with surrogate keys and SCD2 tracking:\n",
    "\n",
    "![Silver Layer Data Model](z_assets/silver-layer-model.png)\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 4.1 Add dbt-utils Package\n",
    "Create `packages.yml` in project root (where `dbt_project.yml` is located):\n",
    "```yaml\n",
    "packages:\n",
    "  - package: dbt-labs/dbt_utils\n",
    "    version: 1.1.1\n",
    "```\n",
    "\n",
    "Install packages:\n",
    "```bash\n",
    "dbt deps\n",
    "```\n",
    "\n",
    "#### 4.2 Update Models with Surrogate Keys\n",
    "Update `src/models/silver/customers.sql`:\n",
    "```sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT \n",
    "    {{ dbt_utils.generate_surrogate_key(['c_custkey']) }} as customer_key,\n",
    "    c_custkey as customer_id,\n",
    "    c_name as customer_name,\n",
    "    c_address as customer_address,\n",
    "    {{ dbt_utils.generate_surrogate_key(['c_nationkey']) }} as nation_key,\n",
    "    c_nationkey as nation_id,\n",
    "    c_phone as customer_phone,\n",
    "    c_acctbal as account_balance,\n",
    "    c_mktsegment as market_segment,\n",
    "    c_comment as customer_comment\n",
    "FROM {{ source('bronze', 'customer') }}\n",
    "```\n",
    "\n",
    "Update all other silver models to include surrogate keys for all ID fields.\n",
    "\n",
    "#### 4.3 Create Snapshots\n",
    "Create `src/snapshots/customers_snapshot.sql`:\n",
    "```sql\n",
    "{% snapshot customers_snapshot %}\n",
    "\n",
    "{{\n",
    "    config(\n",
    "      target_schema='<YOUR INITIALS>_silver_snapshots',\n",
    "      unique_key='customer_id',\n",
    "      strategy='check',\n",
    "      check_cols='all'\n",
    "    )\n",
    "}}\n",
    "\n",
    "SELECT * FROM {{ ref('customers') }}\n",
    "\n",
    "{% endsnapshot %}\n",
    "```\n",
    "\n",
    "Create snapshots for all dimensional tables (customers, orders, parts, suppliers, nations, regions).\n",
    "\n",
    "You don't need to create a snaptshot for `lineitems`, as this table will be used by our fact table. In practice, these types of table don't require SCD2 because:\n",
    "- Transactions are typically immutable (no change)\n",
    "- Massive data volume (performance)\n",
    "- Don't need tracking because only the point-in-time is interesting\n",
    "\n",
    "Contrary to models, the snapshot name is not defined by the filename. The name for the snapshot is specified within the file in the form of `{% snapshot customers_snapshot %}`. For consistency's sake, name the snapshot file the same as the name speficied within the file.\n",
    "\n",
    "#### 4.4 Run Updated Models\n",
    "```bash\n",
    "# Run silver models\n",
    "dbt run --select silver\n",
    "\n",
    "# Run snapshots\n",
    "dbt snapshot\n",
    "\n",
    "# Combined run for model and snapshots\n",
    "dbt build\n",
    "\n",
    "# Wait for the changes in the bronze layer before re-run\n",
    "dbt snapshot\n",
    "```\n",
    "\n",
    "Check for changes in Databricks SQL Editor.\n",
    "```sql\n",
    "-- Check for the changes (replace ek with your initials)\n",
    "SELECT * FROM dbt_workshop.ek_silver_snapshots.customers_snapshot\n",
    "WHERE customer_id IN (412445, 412446, 412447, 412448)\n",
    "ORDER BY customer_id, dbt_valid_from;\n",
    "```\n",
    "\n",
    "### Success Criteria\n",
    "- All models include surrogate keys\n",
    "- Snapshots are created successfully\n",
    "- SCD2 tracking is enabled (check dbt_valid_from, dbt_valid_to columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Gold Layer - Dimensions\n",
    "\n",
    "### Goal\n",
    "Create dimensional model with clean dimension tables.\n",
    "\n",
    "### Gold Layer Data Model\n",
    "Your target star schema for analytics:\n",
    "\n",
    "![Gold Layer Data Model](z_assets/gold-layer-model.png)\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 5.1 Add configuration for gold layer in dbt_project.yml\n",
    "Add information for gold layer in `dbt_project.yml`. The affected section should look like this:\n",
    "```yml\n",
    "models:\n",
    "  dbt_workshop:\n",
    "    silver:\n",
    "      schema: silver\n",
    "      +materialized: table\n",
    "    gold:\n",
    "      schema: gold\n",
    "      +materialized: table\n",
    "```\n",
    "\n",
    "#### 5.2 Configure Gold Models\n",
    "Create `src/models/gold/schema.yml`:\n",
    "```yaml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: dim_customer\n",
    "    description: 'Customer dimension with geography'\n",
    "    columns:\n",
    "      - name: customer_key\n",
    "        description: 'Surrogate key for customer'\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "      - name: customer_id\n",
    "        description: 'Natural key for customer'\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "  \n",
    "  - name: dim_supplier\n",
    "    description: 'Supplier dimension with geography'\n",
    "  \n",
    "  - name: dim_part\n",
    "    description: 'Part dimension'\n",
    "  \n",
    "  - name: fact_lineitem\n",
    "    description: 'Line item fact table'\n",
    "```\n",
    "\n",
    "#### 5.3 Create Customer Dimension\n",
    "Create `src/models/gold/dim_customer.sql`:\n",
    "```sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT \n",
    "    c.customer_key,\n",
    "    c.customer_id,\n",
    "    c.customer_name,\n",
    "    c.customer_address,\n",
    "    c.customer_phone,\n",
    "    c.account_balance,\n",
    "    c.market_segment,\n",
    "    n.nation_name,\n",
    "    r.region_name\n",
    "FROM {{ ref('customers_snapshot') }} c\n",
    "JOIN {{ ref('nations_snapshot') }} n ON c.nation_key = n.nation_key\n",
    "JOIN {{ ref('regions_snapshot') }} r ON n.region_key = r.region_key\n",
    "WHERE c.dbt_valid_to IS NULL  -- Current records only\n",
    "  AND n.dbt_valid_to IS NULL\n",
    "  AND r.dbt_valid_to IS NULL\n",
    "```\n",
    "\n",
    "#### 5.4 Create Supplier Dimension\n",
    "Create `src/models/gold/dim_supplier.sql`:\n",
    "```sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT \n",
    "    s.supplier_key,\n",
    "    s.supplier_id,\n",
    "    s.supplier_name,\n",
    "    s.supplier_address,\n",
    "    s.supplier_phone,\n",
    "    s.account_balance,\n",
    "    n.nation_name,\n",
    "    r.region_name\n",
    "FROM {{ ref('suppliers_snapshot') }} s\n",
    "JOIN {{ ref('nations_snapshot') }} n ON s.nation_key = n.nation_key\n",
    "JOIN {{ ref('regions_snapshot') }} r ON n.region_key = r.region_key\n",
    "WHERE s.dbt_valid_to IS NULL\n",
    "  AND n.dbt_valid_to IS NULL\n",
    "  AND r.dbt_valid_to IS NULL\n",
    "```\n",
    "\n",
    "#### 5.5 Create Part Dimension\n",
    "Create `src/models/gold/dim_part.sql`:\n",
    "```sql\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT \n",
    "    part_key,\n",
    "    part_id,\n",
    "    part_name,\n",
    "    manufacturer,\n",
    "    brand,\n",
    "    part_type,\n",
    "    part_size,\n",
    "    container,\n",
    "    retail_price\n",
    "FROM {{ ref('parts_snapshot') }}\n",
    "WHERE dbt_valid_to IS NULL\n",
    "```\n",
    "\n",
    "#### 5.6 Run Dimension Models\n",
    "```bash\n",
    "dbt run --select gold\n",
    "```\n",
    "\n",
    "#### 5.7 Create Date Dimension\n",
    "\n",
    "For dim_date, we will use seeds. In essence, seeds in dbt is when you upload manual data into the database platform. To do that add the following line add the end of `dbt_project.yml`:\n",
    "\n",
    "```yml\n",
    "seeds:\n",
    "  dbt_workshop:\n",
    "    schema: gold\n",
    "```\n",
    "\n",
    "This line will specifies the target schema to create the table for the seed file.\n",
    "\n",
    "Next, copy the file `dim_date.csv` from `workshop/seed-file` to `src/seeds`. The file name will also define the table name when loading the seed.\n",
    "\n",
    "Finally, load the seed into Databricks with this command (might take up to 5 minutes):\n",
    "```bash\n",
    "dbt seed\n",
    "```\n",
    "\n",
    "Now, the table should be available in Databricks under the schema `<YOUR INITIALS>_gold`.\n",
    "\n",
    "Note: When you run `dbt build`, the process will execute models, snapshots, and seeds. As the seed takes a while to load, please move the seed back to the `seed-file` directory or delete it, to avoid long processing times during the workshop.\n",
    "\n",
    "### Success Criteria\n",
    "- All dimension tables created successfully\n",
    "- Joins between dimensions work correctly\n",
    "- Only current records (dbt_valid_to IS NULL) are included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Gold Layer - Fact Table\n",
    "\n",
    "### Goal\n",
    "Create an incremental fact table for line items.\n",
    "\n",
    "Note: The logic is very flawed and should just showcase the feature for incremental loads. It does not consider changes in lineitems, such as updated dates, etc. It does only look for new orders and append them in the fact table.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 6.1 Create Fact Table\n",
    "Create `src/models/gold/fact_lineitem.sql`:\n",
    "```sql\n",
    "{{\n",
    "    config(\n",
    "        materialized='incremental',\n",
    "        unique_key='order_key || lineitem_key',\n",
    "        incremental_strategy='append',\n",
    "        on_schema_change='fail'\n",
    "    )\n",
    "}}\n",
    "\n",
    "SELECT\n",
    "    l.lineitem_key,\n",
    "    o.order_date,\n",
    "    l.line_number,\n",
    "    -- Foreign keys to dimensions\n",
    "    o.customer_key,\n",
    "    l.part_key,\n",
    "    l.supplier_key,\n",
    "    l.quantity,\n",
    "\n",
    "    -- Measures\n",
    "    l.extended_price,\n",
    "    l.discount,\n",
    "    l.tax,\n",
    "    l.return_flag,\n",
    "    l.line_status,\n",
    "\n",
    "    -- Shipping information and dates formatted for dim_date\n",
    "    date_format(l.ship_date, 'yyyyMMdd') as ship_date,\n",
    "    date_format(l.commit_date, 'yyyyMMdd') as commit_date,\n",
    "    date_format(l.receipt_date, 'yyyyMMdd') as receipt_date,\n",
    "    l.ship_instructions,\n",
    "    l.ship_mode,\n",
    "    \n",
    "    -- Calculated measures\n",
    "    l.extended_price * (1 - l.discount) as discounted_price,\n",
    "    l.extended_price * (1 - l.discount) * (1 + l.tax) as total_price,\n",
    "    \n",
    "    -- Audit fields\n",
    "    o.dbt_updated_at\n",
    "    \n",
    "FROM {{ ref('orders_snapshot') }} o\n",
    "JOIN {{ ref('lineitems') }} l ON o.order_key = l.order_key\n",
    "WHERE o.dbt_valid_to IS NULL\n",
    "\n",
    "{% if is_incremental() %}\n",
    "    -- Only process new orders\n",
    "    AND o.order_date > (SELECT max(order_date) FROM {{ this }})\n",
    "{% endif %}\n",
    "```\n",
    "\n",
    "#### 6.2 Run Fact Table\n",
    "```bash\n",
    "# Initial full load\n",
    "dbt run --select gold.fact_lineitem\n",
    "\n",
    "# Optional: Subsequent incremental runs - you will notice that the run is faster, as we do not have any new data to load\n",
    "dbt run --select gold.fact_lineitem\n",
    "```\n",
    "\n",
    "#### 6.3 Test Your Star Schema\n",
    "Run this query to verify your dimensional model:\n",
    "```sql\n",
    "\n",
    "-- Replace 'ek' with your initials.\n",
    "\n",
    "SELECT\n",
    "    d.date,\n",
    "    d.quarter,\n",
    "    c.customer_name,\n",
    "    c.nation_name,\n",
    "    p.part_name,\n",
    "    s.supplier_name,\n",
    "    f.quantity,\n",
    "    f.total_price\n",
    "FROM ek_gold.fact_lineitem f\n",
    "JOIN ek_gold.dim_customer c ON f.customer_key = c.customer_key\n",
    "JOIN ek_gold.dim_part p ON f.part_key = p.part_key\n",
    "JOIN ek_gold.dim_supplier s ON f.supplier_key = s.supplier_key\n",
    "JOIN ek_gold.dim_date d ON f.ship_date = d.date_key\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "### Success Criteria\n",
    "- Fact table loads successfully\n",
    "- Incremental logic works (run twice to test)\n",
    "- Star schema query returns meaningful results\n",
    "- All foreign key relationships are intact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Testing & Documentation\n",
    "\n",
    "### Goal\n",
    "Add data quality tests and generate documentation.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 7.1 Run Tests\n",
    "```bash\n",
    "dbt test\n",
    "```\n",
    "\n",
    "#### 7.2 Generate Documentation\n",
    "```bash\n",
    "dbt docs generate\n",
    "dbt docs serve\n",
    "```\n",
    "\n",
    "#### 7.3 View Lineage\n",
    "In the docs interface, explore:\n",
    "- Data lineage graph\n",
    "- Model documentation\n",
    "- Test results\n",
    "\n",
    "### Success Criteria\n",
    "- All tests pass\n",
    "- Documentation site loads\n",
    "- Lineage graph shows bronze → silver → gold flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Validation\n",
    "\n",
    "### Check Your Work\n",
    "Run these commands to validate your complete solution:\n",
    "\n",
    "```bash\n",
    "# Run everything\n",
    "dbt build\n",
    "\n",
    "# Check row counts\n",
    "dbt run-operation print_relation_row_counts\n",
    "```\n",
    "\n",
    "### Results\n",
    "You should have:\n",
    "- 8 bronze source tables\n",
    "- 7 silver models + snapshots\n",
    "- 4 gold dimensions + 1 fact table\n",
    "- SCD2 tracking with dbt_valid_from/to\n",
    "- Surrogate keys throughout\n",
    "- Incremental fact table\n",
    "- Star schema for analytics\n",
    "\n",
    "### What You've Learned\n",
    "- dbt project setup and configuration\n",
    "- Source and model definitions\n",
    "- Data transformation and cleansing\n",
    "- Surrogate key generation\n",
    "- SCD2 implementation with snapshots\n",
    "- Dimensional modeling\n",
    "- Incremental models for performance\n",
    "- Testing and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
